{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "((32, 40, 6, 3, 28, 28), (32, 40, 2))"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "X = pickle.load(open('data/X.dat', 'rb'))\n",
    "Y = pickle.load(open('data/Y.dat', 'rb'))\n",
    "\n",
    "(X.shape, Y.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "SEQ_LEN, IMG_CHANNELS, RESOLUTION = X.shape[2:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from src.training import cv_subject, train_subject, finetune_evaluate\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT: 1, CV MSE [0.40406528 0.30275238], CV ACC [0.35 0.6 ]\n",
      "SUBJECT: 2, CV MSE [0.54679906 0.5829817 ], CV ACC [0.55 0.6 ]\n",
      "SUBJECT: 3, CV MSE [0.13510291 0.15464857], CV ACC [0.55 0.8 ]\n",
      "SUBJECT: 4, CV MSE [0.34724063 0.23586233], CV ACC [0.6 0.6]\n",
      "SUBJECT: 5, CV MSE [0.3420049  0.24230602], CV ACC [0.6   0.475]\n",
      "SUBJECT: 6, CV MSE [0.1423387  0.13334192], CV ACC [0.75  0.575]\n",
      "SUBJECT: 7, CV MSE [0.24642369 0.23320922], CV ACC [0.7   0.625]\n",
      "SUBJECT: 8, CV MSE [0.27139825 0.14004673], CV ACC [0.55  0.575]\n",
      "SUBJECT: 9, CV MSE [0.13613693 0.07439212], CV ACC [0.375 0.6  ]\n",
      "SUBJECT: 10, CV MSE [0.28270546 0.14337233], CV ACC [0.475 0.4  ]\n",
      "SUBJECT: 11, CV MSE [0.2916038 0.366479 ], CV ACC [0.55  0.625]\n",
      "SUBJECT: 12, CV MSE [0.32480314 0.18965743], CV ACC [0.425 0.825]\n",
      "SUBJECT: 13, CV MSE [0.35641676 0.25988418], CV ACC [0.55 0.85]\n",
      "SUBJECT: 14, CV MSE [0.36594063 0.18812475], CV ACC [0.225 0.675]\n",
      "SUBJECT: 15, CV MSE [0.3627438  0.11817557], CV ACC [0.5   0.475]\n",
      "SUBJECT: 16, CV MSE [0.21790862 0.22357348], CV ACC [0.625 0.5  ]\n",
      "SUBJECT: 17, CV MSE [0.11668269 0.1194258 ], CV ACC [0.55 0.6 ]\n",
      "SUBJECT: 18, CV MSE [0.09538729 0.11336507], CV ACC [0.6   0.625]\n",
      "SUBJECT: 19, CV MSE [0.21514626 0.19662568], CV ACC [0.575 0.675]\n",
      "SUBJECT: 20, CV MSE [0.1941692  0.09741256], CV ACC [0.575 0.775]\n",
      "SUBJECT: 21, CV MSE [0.23369303 0.11620662], CV ACC [0.525 0.8  ]\n",
      "SUBJECT: 22, CV MSE [0.39245683 0.23650268], CV ACC [0.5 0.6]\n",
      "SUBJECT: 23, CV MSE [0.20625958 0.4086825 ], CV ACC [0.65  0.675]\n",
      "SUBJECT: 24, CV MSE [0.28966945 0.13884991], CV ACC [0.425 0.825]\n",
      "SUBJECT: 25, CV MSE [0.4328018 0.2789873], CV ACC [0.475 0.725]\n",
      "SUBJECT: 26, CV MSE [0.45216995 0.3670846 ], CV ACC [0.65  0.575]\n",
      "SUBJECT: 27, CV MSE [0.3111948  0.38793454], CV ACC [0.75 0.2 ]\n",
      "SUBJECT: 28, CV MSE [0.41729817 0.43097597], CV ACC [0.625 0.5  ]\n",
      "SUBJECT: 29, CV MSE [0.31802794 0.4253784 ], CV ACC [0.55  0.625]\n",
      "SUBJECT: 30, CV MSE [0.12451132 0.12499583], CV ACC [0.675 0.425]\n",
      "SUBJECT: 31, CV MSE [0.29771864 0.4032043 ], CV ACC [0.575 0.1  ]\n",
      "SUBJECT: 32, CV MSE [0.24742393 0.16522583], CV ACC [0.5   0.675]\n"
     ]
    }
   ],
   "source": [
    "from src.model import CNN_LSTM\n",
    "\n",
    "results = []\n",
    "accuracies = []\n",
    "models = []\n",
    "for subject in range(32):\n",
    "    model = CNN_LSTM(2)\n",
    "    cv_loss, cv_accuracies = cv_subject(subject, X, Y, model)\n",
    "\n",
    "    mean_mse, mean_accuracies = np.mean(cv_loss, axis=0), np.mean(cv_accuracies, axis=0)\n",
    "\n",
    "    model, _ = train_subject(subject, X, Y,  CNN_LSTM(2))\n",
    "    models.append(model)\n",
    "\n",
    "    print(f'SUBJECT: {subject + 1}, CV MSE {mean_mse}, CV ACC {mean_accuracies}')\n",
    "\n",
    "    accuracies.append(mean_accuracies)\n",
    "    results.append(mean_mse)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28494513 0.23748952]\n",
      "[0.10818671 0.12326779]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(results, axis=0))\n",
    "print(np.std(results, axis=0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54921875 0.6       ]\n",
      "[0.10977327 0.16286018]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(accuracies, axis=0))\n",
    "print(np.std(accuracies, axis=0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from src.training import MyDataset, train_epoch, evaluate, predict\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "def finetune_evaluate(idx, X, y, model, trial_num):\n",
    "    tx, ty = X[:, :trial_num], y[:, :trial_num]\n",
    "    vx, vy = X[:, 20:], y[:, 20:]\n",
    "\n",
    "    tx, ty = tx[idx].reshape((-1, SEQ_LEN, IMG_CHANNELS, RESOLUTION, RESOLUTION)), ty[idx].reshape((-1, y.shape[-1]))\n",
    "    vx, vy = vx[idx].reshape((-1, SEQ_LEN, IMG_CHANNELS, RESOLUTION, RESOLUTION)), vy[idx].reshape((-1, y.shape[-1]))\n",
    "\n",
    "    val_loss = []\n",
    "    val_accuracies = []\n",
    "    model.train()\n",
    "\n",
    "    iter_no_change = 0\n",
    "    best_model_state = model.state_dict()\n",
    "    best_loss = 0\n",
    "    best_metrics = []\n",
    "\n",
    "    train_dl = DataLoader(MyDataset(tx, ty), batch_size=4, shuffle=True)\n",
    "    val_dl = DataLoader(MyDataset(vx, vy), batch_size=4, shuffle=False)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.01)\n",
    "    model.to('cuda')\n",
    "\n",
    "    for epoch in range(10):\n",
    "        model.train()\n",
    "        epoch_train_loss = train_epoch(model, train_dl, criterion, optimizer)\n",
    "\n",
    "        epoch_val_loss, val_acc, ars_acc = evaluate(*predict(model, val_dl))\n",
    "\n",
    "        if np.mean(epoch_val_loss) < best_loss or epoch == 0:\n",
    "            best_loss = np.mean(epoch_val_loss)\n",
    "            best_metrics = epoch_val_loss, val_acc, ars_acc\n",
    "            iter_no_change = 0\n",
    "            best_model_state = model.state_dict()\n",
    "        else:\n",
    "            iter_no_change += 1\n",
    "\n",
    "        if iter_no_change > 5:\n",
    "            model.load_state_dict(best_model_state)\n",
    "            break\n",
    "\n",
    "    return best_metrics\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT: 25, LOSS 0.5256332159042358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:22<07:09, 22.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT: 25, LOSS 0.43553030490875244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:50<07:42, 25.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT: 25, LOSS 0.3842684030532837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [01:14<07:04, 24.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT: 25, LOSS 0.3124127984046936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [01:38<06:32, 24.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT: 25, LOSS 0.5073813199996948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [02:06<06:27, 25.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT: 25, LOSS 0.421988844871521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [02:34<06:10, 26.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT: 25, LOSS 0.4894446134567261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [03:04<05:59, 27.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT: 25, LOSS 0.46718376874923706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [03:29<05:21, 26.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT: 25, LOSS 0.5210740566253662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [03:55<04:53, 26.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT: 25, LOSS 0.4714527428150177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [04:33<05:00, 30.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT: 25, LOSS 0.5172622799873352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [05:11<04:52, 32.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT: 25, LOSS 0.308277428150177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [05:40<04:11, 31.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT: 25, LOSS 0.31748291850090027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [06:16<03:48, 32.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT: 25, LOSS 0.3005702495574951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [06:48<03:15, 32.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT: 25, LOSS 0.39683881402015686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [07:18<02:39, 31.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT: 25, LOSS 0.4392407536506653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [07:41<01:56, 29.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT: 25, LOSS 0.2810152769088745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [08:07<01:24, 28.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT: 25, LOSS 0.3163915276527405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [08:34<00:55, 27.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT: 25, LOSS 0.3618026375770569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [09:00<00:27, 27.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT: 25, LOSS 0.4254027009010315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [09:23<00:00, 28.19s/it]\n"
     ]
    }
   ],
   "source": [
    "from src.model import EnsembleModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "trial_data = {}\n",
    "for trial_num in tqdm(range(1, 21)):\n",
    "    loss_arr = []\n",
    "    metrics_arr = []\n",
    "    for subject in range(24, 32):\n",
    "        ensemble = EnsembleModel(models[:24])\n",
    "        metrics = finetune_evaluate(subject, X, Y, ensemble, trial_num)\n",
    "        loss = np.mean(metrics[0])\n",
    "        metrics_arr.append(metrics)\n",
    "\n",
    "        if subject == 24:\n",
    "            print(f'SUBJECT: {subject + 1}, LOSS {loss}')\n",
    "\n",
    "    trial_data[trial_num] = [loss_arr, metrics_arr]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "((1, 32, 6, 3, 28, 28), (1, 32, 2))"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pickle.load(open('eeg-experiment/X.dat', 'rb'))\n",
    "Y = pickle.load(open('eeg-experiment/Y.dat', 'rb'))\n",
    "\n",
    "(X.shape, Y.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "tx, vx = X[:, :16], X[:, 16:]\n",
    "ty, vy = Y[:, :16], Y[:, 16:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "0.20119953155517578"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject = 0\n",
    "\n",
    "model, loss = train_subject(subject, tx, ty,  CNN_LSTM(Y.shape[-1]))\n",
    "loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "eeg-torch",
   "language": "python",
   "display_name": "eeg-torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
